# Titanic Data Analysis and Machine Learning Pipeline

## Overview
This project focuses on understanding, cleaning, and preparing the Titanic dataset for machine learning. The workflow includes exploratory data analysis, feature classification, handling missing values, encoding categorical features, and building a basic machine learning model to predict passenger survival.

## Dataset
- Titanic Dataset
- Each record represents a passenger and their travel details

## Tools & Technologies
- Python
- Pandas
- NumPy
- Scikit-learn
- Matplotlib
- Jupyter Notebook / VS Code

## Project Workflow
- Loaded and explored the dataset structure and features
- Identified numerical and categorical data types
- Analyzed missing values and data quality issues
- Performed data cleaning and preprocessing
- Encoded categorical variables for ML readiness
- Built and evaluated a Logistic Regression model

## Machine Learning
- Problem Type: Binary Classification
- Target Variable: `Survived`
- Model Used: Logistic Regression
- Evaluation Metrics: Accuracy, Classification Report, Confusion Matrix

## Results & Observations
- The dataset required preprocessing before modeling
- The trained model achieved reasonable performance in predicting survival
- Both survivors and non-survivors were identified with good accuracy

## Conclusion
This project demonstrates a complete end-to-end data analysis and machine learning pipeline. It highlights the importance of data understanding and preprocessing as foundational steps for effective predictive modeling.

